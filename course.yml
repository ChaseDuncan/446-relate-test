chunks:

    # {{{ metadata

    -
        title: "About the class"
        id: about
        rules:
            - weight: 1000

        content: |

            # Machine Learning (CS 446) Fall 2017

            | What                           | Where
            | ------------------------------ | ----------------------------------------------------------------------------------------------
            | **Time/place**                 | **Section M:** TTh 12:30pm-1:45pm 1404 [SC](https://illinois.edu/map/view?skinId=0&ACTION=MAP&buildingId=210) / [Catalog](https://courses.illinois.edu/schedule/2017/spring/CS/357)
            | **Class URL**                  | <https://bit.ly/cs357-s17>
            | **Class recordings**           | <a href="https://recordings.engineering.illinois.edu:8443/ess/portal/section/aba7c116-653b-4f91-a8b8-219bd3419142 ">Watch &raquo;</a> (Section M)
            | **Web forum**                  | <a href="https://piazza.com/class/j6wdblircag49w" target="_blank" role="button" class="btn btn-default">Discuss &raquo;</a>
            | **Calendar**                   | <a href="calendar:" role="button" class="btn btn-default">View &raquo;</a>

            ## Course Description
            
            The goal of Machine Learning is to build computer systems that can adapt and learn from their experience. 
            This course will study the theory and application of learning methods that have proved valuable and 
            successful in practical applications. We review the theory of machine learning in order to get a good 
            understanding of the basic issues in this area, and present the main paradigms and techniques needed to 
            obtain successful performance in application areas such as natural language and text understanding, 
            speech recognition, computer vision, data mining, adaptive computer systems and others. The main body 
            of the course will review several supervised and (semi/un)supervised learning approaches. These include 
            methods for learning linear representations, Bayesian / Probabilistic methods, decision-tree methods, 
            kernel based methods and neural networks, as well as clustering and dimensionality reduction techniques. 
            We will also discuss how to model machine learning problems and discuss some open problems.

            ### Topics to be covered include:
            
            *Linear/Logistic Regression
            *Variable Selection / Sparsity 
            *Optimization - Gradient Descent
            *Support Vector Machines
            *Convolutional/Recurrent Neural Networks
            *Clustering
            *Graphical Models
            *Expectation Maximization
            *Variational Inference
            *Generative Adversarial Networks
            *Multilabel Classification
            *Structured Prediction

            ### Required text
            Text: [Kevin Murphy, Machine Learning: A Probabilistic Perspective, MIT Press]
            (https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020/ref=sr_1_1?ie=UTF8&qid=1504017924&sr=8-1&keywords=probabilistic+machine+learning)

    # }}}

    # {{{ assignments

    -
        title: "Assignments"
        id: assignments
        rules:
            - weight: 100

        content: |

            ## Exams

            Please find information on our upcoming exams in the corresponding
            section of the  [class calendar](calendar:).

            ## Homework

            Please see the [class calendar](calendar:) for homework deadlines
            (generally Fridays at 5 pm, except for examlet weeks).

    # }}}


    # {{{ resources

    -
        title: "Resources"
        id: resources
        rules:
            - weight: 0

        content: |

            ## Computing

            We will be using [Python](http://python.org) with the libraries
            [numpy](http://docs.scipy.org/doc/numpy/user/),
            [scipy](http://docs.scipy.org/doc/scipy/reference/) and
            [matplotlib](http://matplotlib.org/) for in-class work and
            assignments. No other languages are permitted. Python has a very
            gentle learning curve, so you should feel at home even if you've
            never done any work in Python.

            ## Additional reading

            *Shai Shalev-Shwartz and Shai Ben-David, Understanding Machine Learning: From Theory to Algorithms, Cambridge University Press
            *Trevor Hastie Robert Tibshirani & Jerome Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer Science & Business Media
            *C.M. Bishop, Pattern Recognition and Machine Learning, Springer
            *Tom Mitchell, Machine Learning, McGraw Hill
            *Ian Goodfellow, Yoshua Bengio & Aaron Courville, Deep Learning, The MIT Press

    # }}}

    # {{{ policies

    -
        title: "Policies"
        id: policies
        rules:
            - if_before: lecture_m 5
              weight: 200
              shown: true

            - weight: 0
              shown: true

        content: |

            ## Grading Policies

            <a href="staticpage:policies" role="button"
            class="btn btn-primary">View policies &raquo;</a>

    # }}}

    # {{{ references

    -
        title: "References"
        id: references
        rules:
        -   weight: 0

        content: |

            ## Python Help

            (see section 1 of the outline for more)

            *   [**The Scipy Lectures**](http://www.scipy-lectures.org/)
            *   [Dive into Python 3](http://www.diveinto.org/python3/)
            *   [Learn Python the hard way](http://learnpythonthehardway.org/)
            *   [Python tutorial](https://docs.python.org/3/tutorial/index.html)
            *   [Facts and myths about Python names and values](http://nedbatchelder.com/text/names.html)
            *   [CSE workshop training material](https://github.com/uiuc-cse/python-sp16)
            *   [From Python to Numpy](http://www.labri.fr/perso/nrougier/from-python-to-numpy/)
                (An open-access book on numpy vectorization techniques, Nicolas P. Rougier, 2017)

            ### Numpy Help

            * [Introduction to Python for Science](https://github.com/djpine/pyman)
            * [Numpy/Scipy documentation](http://docs.scipy.org/doc/)
            * [More in this reddit thread](http://www.reddit.com/r/Python/comments/1lgxbf/best_tutorial_to_learn_numpy/)
            * [An introduction to Numpy and SciPy](http://www.engr.ucsb.edu/~shell/che210d/numpy.pdf)
            * [100 Numpy exercises](http://www.loria.fr/~rougier/teaching/numpy.100/index.html)
            * [The Numpy MedKit](http://mentat.za.net/numpy/numpy_advanced_slides/) by St√©fan van der Walt

            ## Linear Algebra

            *   [Immersive Linear Algebra](http://immersivemath.com/ila/)
            *   [Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) 
                (YouTube, by 3Blue1Brown)
            *   [Linear Algebra](https://www.youtube.com/channel/UCr22xikWUK2yUW4YxOKXclQ/playlists)
                (YouTube, by MathTheBeautiful)

            ## Statistics (goes beyond class material)

            * [Statistics for Hackers](https://speakerdeck.com/jakevdp/statistics-for-hackers) by Jake VanderPlas

    # }}}

# vim: fdm=marker:textwidth=85
